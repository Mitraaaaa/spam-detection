{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score , accuracy_score\n",
    "import crossovers\n",
    "from imblearn.over_sampling import BorderlineSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(sms_data_str):\n",
    "    \"\"\"\n",
    "    convert `sms_data_str` into a pandas dataframe\n",
    "    \"\"\"\n",
    "    data_arr = []\n",
    "\n",
    "    data_records = sms_data_str.split('\\n')[:-1]\n",
    "    for data in data_records:\n",
    "        label = None\n",
    "        sample = None\n",
    "        match data[:3]:\n",
    "            case 'ham':\n",
    "                label = 'legitimate'\n",
    "                sample = data[4:] \n",
    "            case 'spa':\n",
    "                label = 'spam'\n",
    "                sample = data[5:] \n",
    "            case _:\n",
    "                label = 'N/A'\n",
    "            \n",
    "        data_arr.append([label, sample])\n",
    "        \n",
    "    data_arr = np.array(data_arr)\n",
    "    data_label = data_arr[:, 0]\n",
    "    data_records = data_arr[:, 1]\n",
    "    \n",
    "    return data_records, data_label\n",
    "\n",
    "def tfidf_vectorizer(records):\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        lowercase=True,\n",
    "        token_pattern=r'\\b[A-Za-z]+\\b', \n",
    "        norm=None\n",
    "    )\n",
    "    \n",
    "    records_transformed = vectorizer.fit_transform(records)\n",
    "\n",
    "    return records_transformed.toarray(), vectorizer.get_feature_names_out()\n",
    "\n",
    "def feature_extraction(X, n_components=5):\n",
    "    reduction_pca = PCA(\n",
    "        n_components=n_components,\n",
    "        whiten=False\n",
    "    )\n",
    "    data_reduced = reduction_pca.fit_transform(X)\n",
    "    return data_reduced\n",
    "\n",
    "def feature_selection(df_records, labels, n_components=5):\n",
    "    feature_selection_model = SelectKBest(mutual_info_classif, k=n_components) \n",
    "    ## make a selection over the best features\n",
    "    selected_record_features = feature_selection_model.fit_transform(df_records, labels)\n",
    "    \n",
    "    return selected_record_features, feature_selection_model.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_data_str = None\n",
    "with open('SMSSpamCollection') as file:\n",
    "    sms_data_str = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, labels = process_data(sms_data_str)\n",
    "records_vectorized, feature_names = tfidf_vectorizer(records)\n",
    "\n",
    "## one hot encoding labels\n",
    "labels = np.array([0 if y == 'legitimate' else 1 for y in labels] )\n",
    "\n",
    "## reducing dimension\n",
    "records_dim_reduced = feature_extraction(records_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.85640917,  0.28668657, -1.18546882,  0.8256663 ,  0.74978327],\n",
       "       [-2.78399012,  0.52133197, -1.7417723 ,  0.5025835 , -0.72640112],\n",
       "       [ 0.48296358, -0.03635116,  2.00763173, -6.52282026,  1.10384236],\n",
       "       [-1.83559234,  1.14068218, -3.93162367, -0.18419417, -1.96588603],\n",
       "       [ 0.27688356, -0.7748319 ,  0.10924085,  1.32256079, -0.72450084]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_dim_reduced[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_vectorized = pd.DataFrame(records_vectorized, columns=feature_names)\n",
    "\n",
    "records_selection, feature_name_selection = feature_selection(records_vectorized,labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>call</th>\n",
       "      <th>free</th>\n",
       "      <th>prize</th>\n",
       "      <th>to</th>\n",
       "      <th>txt</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.187968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.584244</td>\n",
       "      <td>4.51406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.194748</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>3.3125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.183396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.194748</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.187968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.194748</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.194748</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5574 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        call      free     prize        to      txt  labels\n",
       "0     0.0000  0.000000  0.000000  0.000000  0.00000       0\n",
       "1     0.0000  0.000000  0.000000  0.000000  0.00000       0\n",
       "2     0.0000  4.187968  0.000000  6.584244  4.51406       1\n",
       "3     0.0000  0.000000  0.000000  0.000000  0.00000       0\n",
       "4     0.0000  0.000000  0.000000  2.194748  0.00000       0\n",
       "...      ...       ...       ...       ...      ...     ...\n",
       "5569  3.3125  0.000000  5.183396  0.000000  0.00000       1\n",
       "5570  0.0000  0.000000  0.000000  2.194748  0.00000       0\n",
       "5571  0.0000  0.000000  0.000000  0.000000  0.00000       0\n",
       "5572  0.0000  4.187968  0.000000  2.194748  0.00000       0\n",
       "5573  0.0000  0.000000  0.000000  2.194748  0.00000       0\n",
       "\n",
       "[5574 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## for better visualization\n",
    "df = pd.DataFrame(records_selection, columns=feature_name_selection)\n",
    "df['labels'] = labels\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide our dataset to spam and ham parts for feeding to the model!\n",
    "X_resampled, y_resampled = BorderlineSMOTE().fit_resample(records_selection, labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "spam_dataset = df[df['labels']==1]\n",
    "ham_dataset = df[df['labels']==0]\n",
    "\n",
    "spam_dataset = []\n",
    "spam_labels = []\n",
    "ham_dataset = []\n",
    "ham_labels = []\n",
    "\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    if y_train[i] == 1:\n",
    "        spam_dataset.append(X_train[i])\n",
    "        spam_labels.append(y_train[i])\n",
    "    else:\n",
    "        ham_dataset.append(X_train[i])\n",
    "        ham_labels.append(y_train[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chromosome:\n",
    "    def __init__(self, m=None, s=None):\n",
    "        # rule = [[['x1','h'],['x2','l'],.......,['label','0']],[...],...]\n",
    "        self.rules = []\n",
    "        # determine the function of rules tri,sigmoid,...\n",
    "        self.functions = []\n",
    "        # determine the m,s values for the rules\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        # determine the cf for the chromosome\n",
    "        self.cf = []\n",
    "        # to do\n",
    "        # add don't care as linguistic_terms\n",
    "        # number of features in rules can vary -> 1 feature to 5 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_total_range(data):\n",
    "    min_feature = np.min(data)\n",
    "    max_feature = np.max(data)\n",
    "    return min_feature,max_feature\n",
    "\n",
    "def s_m_init(min_feature,max_feature):\n",
    "    step = math.ceil((max_feature-min_feature) /5)\n",
    "    m_list = []\n",
    "    s_list = []\n",
    "    # 0 23 4 , 0 , 4, 8, 12 , 16 , 20\n",
    "    if int(min_feature == 0):\n",
    "        min_feature = 0.1\n",
    "    for i in range(int(min_feature), int(max_feature), step):\n",
    "        m_list.append(random.uniform(i, i+step))\n",
    "\n",
    "    total_dist = 0 \n",
    "    # min_dist = 10000000\n",
    "    max_dist = -1\n",
    "    for i in range(0,len(m_list)-1):\n",
    "        max_dist = max(max_dist, m_list[i+1]-m_list[i])\n",
    "        # min_dist = min(min_dist, m_list[i+1]-m_list[i])\n",
    "        total_dist += m_list[i+1]-m_list[i]\n",
    "\n",
    "    avg_dist = total_dist / step\n",
    "    for i in range(int(min_feature), int(max_feature), step):\n",
    "        s_list.append(random.uniform(random.uniform(0.001,avg_dist),random.uniform(avg_dist,max_dist)))\n",
    "\n",
    "\n",
    "    return m_list, s_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(func, x, m , s):\n",
    "    if func == 'tri':\n",
    "       left = (x - m + s) / s\n",
    "       right = (m + s - x) / s\n",
    "       return max(min(left, right), 0)\n",
    "    \n",
    "    elif func == 'rect-trap':\n",
    "        return max( min ((x-m+s)/s, 1),0)\n",
    "    \n",
    "    elif func == 'gaussian':\n",
    "        return math.exp((-1/2)*((x-m)/s)**2)\n",
    "    \n",
    "    elif func == 'sigmoid':\n",
    "        return 1 / (1 + math.exp(-((x-m)/s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: build a fuzzy rule-based model for (records, label)\n",
    "initial_functions = ['tri', 'rect-trap', 'gaussian', 'sigmoid']\n",
    "linguistic_terms = ['vl', 'l', 'm', 'h', 'vh', 'X']\n",
    "\n",
    "\n",
    "def get_individuals(individuals, population_size, number_of_rules):\n",
    "    min_feature, max_feature = find_total_range(X_train)\n",
    "    for _ in range(population_size):\n",
    "        chromosome = Chromosome()\n",
    "\n",
    "        # determine s, m of chromosome\n",
    "        s, m = s_m_init(min_feature, max_feature)\n",
    "        chromosome.m = m\n",
    "        chromosome.s = s\n",
    "        \n",
    "        # determine functions for linguistic_terms\n",
    "        # number_of_linguistic_terms = random.randint(3,5)\n",
    "        number_of_linguistic_terms = 5\n",
    "        for _ in range(number_of_linguistic_terms):\n",
    "            random_function_index = random.randint(0, len(initial_functions) - 1)\n",
    "            chromosome.functions.append(initial_functions[random_function_index])\n",
    "        \n",
    "        # determine rules of chromosome\n",
    "        for _ in range(number_of_rules):        \n",
    "            rule = []\n",
    "            for i in range(5):\n",
    "                linguistic_term_selection = linguistic_terms[random.randint(0, len(linguistic_terms) - 1)]\n",
    "                rule.append([f'x{i+1}', linguistic_term_selection])\n",
    "            rule.append(['label', random.randint(0, 1)])\n",
    "            # update our chromosome\n",
    "            chromosome.rules.append(rule)\n",
    "            chromosome.cf = []\n",
    "            \n",
    "        # add chromosome to individuals list\n",
    "        individuals.append(chromosome)\n",
    "        \n",
    "    return individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "# def calculate_membership(chromosome, features):\n",
    "#     output = [0, 0]\n",
    "#     for rule in chromosome.rules:\n",
    "#         value = 1\n",
    "#         x_num = 0 \n",
    "#         for i in range(len(features)):\n",
    "#             # x ['x1', 'l']\n",
    "#             if rule[i][1] == 'X':\n",
    "#                 x_num += 1\n",
    "#                 value *= 1\n",
    "#                 continue\n",
    "#             index = linguistic_terms.index(rule[i][1])\n",
    "#             m = chromosome.m[index]\n",
    "#             s = chromosome.s[index]\n",
    "#             tmp = function(chromosome.functions[index], features[i], m, s)\n",
    "#             if random.randint(0, 1) == 0:\n",
    "#                 value *= (1 - tmp)\n",
    "#             else : value *= tmp\n",
    "#         if x_num == len(features):\n",
    "#             value = 0\n",
    "#         if rule[5][1] == 0:\n",
    "#             output[0] += value\n",
    "#         else:\n",
    "#             output[1] += value\n",
    "#     return output\n",
    "\n",
    "def calculate_membership(rule, features, chromosome):\n",
    "    value = 1\n",
    "    x_num = 0 \n",
    "    for x in rule:\n",
    "        # x -> ['x1' 'l']\n",
    "        if x[0] == 'label':\n",
    "            break\n",
    "        \n",
    "        for i in range(len(features)):\n",
    "            if x[1] == 'X':\n",
    "                x_num += 1\n",
    "                value *= 1\n",
    "                continue\n",
    "            index = linguistic_terms.index(x[1])\n",
    "            m = chromosome.m[index]\n",
    "            s = chromosome.s[index]\n",
    "            tmp = function(chromosome.functions[index], features[i], m, s)\n",
    "            if random.randint(0, 1) == 0:\n",
    "                value *= (1 - tmp)\n",
    "            else : value *= tmp\n",
    "    if x_num == len(features):\n",
    "        value = 0\n",
    "    return value\n",
    "\n",
    "\n",
    "\n",
    "def calculate_cf(chromosome, gc, true_label):\n",
    "    # print('calculate cf:',gc,true_label)\n",
    "    if gc[0] == 0 and gc[1] == 0:\n",
    "        chromosome.cf = 0\n",
    "    else:\n",
    "        if true_label == 0:\n",
    "            f_c = gc[0]\n",
    "            f_neg = gc[1]\n",
    "        else:\n",
    "            f_c = gc[1]\n",
    "            f_neg = gc[0]\n",
    "        cf = (f_c - f_neg) / (f_c + f_neg)\n",
    "        chromosome.cf = cf\n",
    "        \n",
    "def select_random_input(mode):\n",
    "\n",
    "    if mode == 1:\n",
    "        index = random.randint(0, len(spam_dataset) - 1)\n",
    "        features = spam_dataset[index]\n",
    "        label = spam_labels[index]\n",
    "        # features = spam_dataset.iloc[index][:-1]\n",
    "        # label = spam_dataset.iloc[index][-1]\n",
    "\n",
    "    else:\n",
    "        ham_index = random.randint(0, len(ham_dataset) - 1)\n",
    "        # features = ham_dataset.iloc[ham_index][:-1]\n",
    "        # label = ham_dataset.iloc[ham_index][-1]\n",
    "        features = ham_dataset[ham_index]\n",
    "        label = ham_labels[ham_index]\n",
    "\n",
    "\n",
    "    return features,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_crossover(individuals):\n",
    "\n",
    "    P_cro_labels = 0.5\n",
    "\n",
    "    cf_list = []\n",
    "    for chromosome in individuals:\n",
    "        cf_list.append(chromosome.cf)\n",
    "\n",
    "    weighted_cf = []\n",
    "    for i in range(len(cf_list)):\n",
    "        weighted_cf.append(cf_list[i] / np.sum(cf_list))\n",
    "    \n",
    "    # select 2 chromosomes as parents\n",
    "    parent1 = random.randint(0, len(individuals) - 1)\n",
    "    parent2 = random.randint(0, len(individuals) - 1)\n",
    "\n",
    "    # make child elements\n",
    "    # new rules\n",
    "\n",
    "    final_child_rules1 = []\n",
    "    final_child_rules2= []\n",
    "\n",
    "    for rule_ind in range (len(individuals[parent1].rules)):\n",
    "        child1_rules = []\n",
    "        child2_rules = []\n",
    "        #Extract the seocond part (e.g: [x1,l] => l)\n",
    "        var_terms1 = []\n",
    "        var_terms2 = []\n",
    "        for each in individuals[parent1].rules[rule_ind]:\n",
    "            var_terms1.append(each[1])\n",
    "        for each in individuals[parent2].rules[rule_ind]:\n",
    "            var_terms2.append(each[1])\n",
    "\n",
    "        # print('var_terms:', var_terms1, var_terms2)\n",
    "        rules1, rules2 = crossovers.two_point_crossover(var_terms1[:-1], var_terms2[:-1])\n",
    "\n",
    "\n",
    "        if random.random() <= P_cro_labels:\n",
    "            rules1.append(var_terms2[-1])\n",
    "            rules2.append(var_terms1[-1])\n",
    "        else:\n",
    "            rules2.append(var_terms2[-1])\n",
    "            rules1.append(var_terms1[-1])\n",
    "\n",
    "\n",
    "        for index , each in enumerate(individuals[parent1].rules[rule_ind]):\n",
    "            child1_rules.append([each[0],rules1[index]])\n",
    "        for index , each in enumerate(individuals[parent2].rules[rule_ind]):\n",
    "            child2_rules.append([each[0],rules2[index]])\n",
    "\n",
    "        final_child_rules1.append(child1_rules)\n",
    "        final_child_rules2.append(child2_rules)\n",
    "        \n",
    "    # new m\n",
    "    m1, m2 = crossovers.two_point_crossover(individuals[parent1].m, individuals[parent2].m)\n",
    "    # new s\n",
    "    s1, s2 = crossovers.two_point_crossover(individuals[parent1].s, individuals[parent2].s)\n",
    "    \n",
    "    function1, function2 = crossovers.two_point_crossover(individuals[parent1].functions, individuals[parent2].functions)\n",
    "    \n",
    "    child1 = Chromosome(m1, s1)\n",
    "    child2 = Chromosome(m2, s2)\n",
    "\n",
    "\n",
    "    child1.rules = final_child_rules1\n",
    "    child2.rules = final_child_rules2\n",
    "\n",
    "\n",
    "    child1.functions = function1\n",
    "    child2.functions = function2\n",
    "\n",
    "\n",
    "    return child1, child2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutataion(chromosome, min_feature, max_feature):\n",
    "    for rule in chromosome.rules:\n",
    "        for x in rule:\n",
    "            if x[1] == 'X' and random.randint(0, 1) == 1:\n",
    "                random_linguistic_index = random.randint(0, len(linguistic_terms) - 1)\n",
    "                x[1] = linguistic_terms[random_linguistic_index]\n",
    "\n",
    "    for j in range(len(chromosome.functions)):\n",
    "        if random.randint(0, 1) == 0:\n",
    "            chromosome.functions[j] = initial_functions[random.randint(0, len(initial_functions) - 1)]\n",
    "            \n",
    "    m , s = s_m_init(min_feature, max_feature)\n",
    "    chromosome.m = m\n",
    "    chromosome.s = s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(individuals, mode):\n",
    "    predicted_labels = []\n",
    "    if mode == 'test':\n",
    "        for features in X_test:\n",
    "            gc = [0,0]\n",
    "            for chromosome in individuals:\n",
    "                for rule in chromosome.rules:\n",
    "                    value = calculate_membership(rule, features, chromosome)\n",
    "                    if rule[-1][1] == 0:\n",
    "                        gc[0] += value\n",
    "                    else:\n",
    "                        gc[1] += value\n",
    "            predicted = np.argmax(gc)\n",
    "            predicted_labels.append(predicted)\n",
    "    else:\n",
    "        for features in X_train:\n",
    "            gc = [0,0]\n",
    "            for chromosome in individuals:\n",
    "                for rule in chromosome.rules:\n",
    "                    value = calculate_membership(rule, features, chromosome)\n",
    "                    if rule[-1][1] == 0:\n",
    "                        gc[0] += value\n",
    "                    else:\n",
    "                        gc[1] += value\n",
    "            predicted = np.argmax(gc)\n",
    "            predicted_labels.append(predicted)            \n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EA(generations, P_mut, P_cro, population_size, number_of_rules):\n",
    "\n",
    "    individuals = []\n",
    "    individuals = get_individuals(individuals, population_size, number_of_rules)\n",
    "\n",
    "    # find cf of initial individuals\n",
    "    for chromosome in individuals:\n",
    "        for rule in chromosome.rules:\n",
    "            fc = 0\n",
    "            fneg = 0\n",
    "            for each_sample in range(len(X_train)):\n",
    "                value = calculate_membership(rule, X_train[each_sample], chromosome)\n",
    "                if rule[-1][1] == y_train[each_sample]:\n",
    "                    fc += value\n",
    "                else:\n",
    "                    fneg += value\n",
    "            if fc == 0 and fneg == 0:\n",
    "                chromosome.cf.append(0)\n",
    "            else:\n",
    "                cf = (fc- fneg) / (fc + fneg)                \n",
    "                chromosome.cf.append(cf)\n",
    "                \n",
    "                    \n",
    "\n",
    "    # evolutionary algorithm\n",
    "    for generation in range(generations):\n",
    "\n",
    "        # making childs\n",
    "        for _ in range(population_size):\n",
    "            if random.random() < P_cro:\n",
    "                child1, child2 = make_crossover(individuals)\n",
    "\n",
    "                for chromosome in [child1, child2]:\n",
    "                    for rule in chromosome.rules:\n",
    "                        for each_sample in range(len(X_train)):\n",
    "                            value = calculate_membership(rule, X_train[each_sample], chromosome)\n",
    "                            if rule[-1][1] == y_train[each_sample]:\n",
    "                                fc += value\n",
    "                            else:\n",
    "                                fneg += value\n",
    "                        if fc == 0 and fneg == 0:\n",
    "                            chromosome.cf.append(0)\n",
    "                        else:\n",
    "                            cf = (fc- fneg) / (fc + fneg)\n",
    "                            chromosome.cf.append(cf)\n",
    "        \n",
    "                if random.random() < P_mut:\n",
    "                    mutataion(child1, np.min(X_train), np.max(X_train))\n",
    "                    mutataion(child2, np.min(X_train), np.max(X_train))\n",
    "\n",
    "                for chromosome in [child1, child2]:\n",
    "                    individuals.append(chromosome)\n",
    "\n",
    "        individuals.sort(key=lambda x: np.sum(x.cf), reverse=True)\n",
    "        individuals = individuals[:population_size]\n",
    "\n",
    "                   \n",
    "    return individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Train:  49.88993914282015\n",
      "Accuracy Test:  48.10978767477991\n",
      "F1 test:  0.6230248306997742\n",
      "F1 train:  0.6409352384486918\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_test = 0.0\n",
    "total_train = 0.0\n",
    "\n",
    "individuals = []\n",
    "individuals = EA(5, 0.9, 0.9, 25, 4)\n",
    "\n",
    "predicted_labels_test = calculate_accuracy(individuals, 'test')\n",
    "predicted_labels_train = calculate_accuracy(individuals, 'train')\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, predicted_labels_train) * 100\n",
    "accuracy_test = accuracy_score(y_test, predicted_labels_test) * 100\n",
    "\n",
    "print('Accuracy Train: ', accuracy_train)\n",
    "print('Accuracy Test: ', accuracy_test)\n",
    "print('F1 test: ', f1_score(y_test, predicted_labels_test))\n",
    "print('F1 train: ', f1_score(y_train, predicted_labels_train))\n",
    "\n",
    "\n",
    "    # our_labels_test = find_predicted_labels('test', dic)\n",
    "    # our_labels_train = find_predicted_labels('train', dic)\n",
    "\n",
    "    # total_train += accuracy_score(y_train,our_labels_train)\n",
    "    # total_test += accuracy_score(y_test, our_labels_test)\n",
    "    # our_labels_train = calculate_accuracy('train', dic)\n",
    "    # our_labels_test = calculate_accuracy('test', dic)\n",
    "    \n",
    "    # total_test += np.mean(np.array(y_test) == np.array(our_labels_test))\n",
    "    # total_train += np.mean(np.array(y_train) == np.array(our_labels_train))\n",
    "\n",
    "# for i in [0,1]:\n",
    "#     for chromosome in dic[i]:\n",
    "#         print(chromosome.rules[0])\n",
    "\n",
    "# x1 = f1_score(y_train,our_labels_train)\n",
    "# x2 = f1_score(y_test,our_labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_test = [48.10978767477991]\n",
    "array_train = [49.88993914282015]\n",
    "f1_test = [ 0.6230248306997742]\n",
    "f1_train = [0.6409352384486918]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37043166ea18f5b7b1250106bf7bda67818b4f566414d693f9a8a609cb777cca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
